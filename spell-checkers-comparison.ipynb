{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "### Dataset format\n",
    "\n",
    "The analyzed dataset is a set of english correctly spelled words as well as variations of their incorrect spelling, collected by Wikipedia editors. Most of the spell checking tools support the ability to find errors and correct them in English texts, so English was selected for testing. File with the data can be downloaded from this [article](https://www.kaggle.com/datasets/bittlingmayer/spelling?resource=download&select=wikipedia.txt) (file ['wikipedia_misspells.txt'](https://github.com/diffitask/spell-checkers-comparison/blob/main/data/wikipedia_misspells.txt) has already been downloaded and put in the *data* folder)\n",
    "\n",
    "Also, there are interesting ways to generate misspelled words from the correct ones described in this [article](https://www.ijcaonline.org/archives/volume176/number27/yunus-2020-ijca-920288.pdf), where it is suggested to swap letters, add new letters and use keyboard characters relative positions. However, in this work I have so far stopped at the Wikipedia dataset described above.\n",
    "\n",
    "### Where to download more datasets for testing\n",
    "\n",
    "For the dataset parsing method presented here, any files with data in the following format will be suitable:\n",
    "*{'the correct word': 'its incorrect spelling 1', 'incorrect spelling 2', ..., 'incorrect spelling N'}*\n",
    "For example, [this](https://www.kaggle.com/datasets/bittlingmayer/spelling?select=aspell.txt), [this](https://www.kaggle.com/datasets/bittlingmayer/spelling?select=birkbeck.txt) and [this](https://www.kaggle.com/datasets/bittlingmayer/spelling?select=spell-testset2.txt) datasets from the site mentioned above can also be used in testing.\n",
    "\n",
    "### Dataset reading and dictionary creating\n",
    "\n",
    "Because a different number of potential misspelled forms are presented for each correct word in the dataset, it's impossible to use the *read_csv* method from *pandas* library, where it's required the same number of columns-features for each row. So the dataset will be processed line by line."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def read_misspells_dataset(path_to_misspells_file: str) -> dict:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_misspells_file : str\n",
    "        Path to the dataset file (may have any format).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataset_dict : dict\n",
    "        Dictionary from misspelled dataset word to list of its possible correct spellings.\n",
    "\n",
    "    \"\"\"\n",
    "    # reading dataset file\n",
    "    with open(path_to_misspells_file, 'r') as dataset_file:\n",
    "        dataset_lines = dataset_file.readlines()\n",
    "\n",
    "    # delete '\\n' symbols\n",
    "    dataset_lines = [line.strip() for line in dataset_lines]\n",
    "\n",
    "    # filling dataset dictionary\n",
    "    dataset_dict = {}\n",
    "    for word_line in dataset_lines:\n",
    "        line_words = word_line.split()\n",
    "        correct_word = line_words[0][:-1]  # removing ':'\n",
    "\n",
    "        misspellings = []\n",
    "        if len(line_words) > 1:\n",
    "            misspellings = line_words[1:]\n",
    "        dataset_dict[correct_word] = misspellings\n",
    "\n",
    "    return dataset_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test dataset reading result\n",
    "Dataset is huge enough, so let's print first 1000 symbols of a string representation of the resulting dictionary, to see if everything was processed correctly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apennines': ['Apenines', 'Appenines'], 'Athenian': ['Athenean'], 'Athenians': ['Atheneans'], 'Bernoulli': ['Bernouilli'], 'Blitzkrieg': ['Blitzkreig'], 'Brazilian': ['Brasillian'], 'Britain': ['Britian'], 'British': ['Brittish'], 'Caesar': ['Ceasar'], 'Cambridge': ['Cambrige'], 'Caracas': ['carcas'], 'Caribbean': ['Carribean'], 'Carthaginian': ['Carthagian'], 'Catalina': ['Cataline'], 'Catiline': ['Cataline'], 'Celsius': ['Celcius'], 'Champagne': ['Champange'], 'Connecticut': ['Conneticut'], 'Cypriot': ['Cyprian'], 'Ellis': ['eles'], 'English': ['Enlish'], 'European': ['Europian', 'Eurpean', 'Eurpoean'], 'Europeans': ['Europians'], 'February': ['febuary'], 'Flemish': ['Flemmish'], 'Franciscan': ['Fransiscan'], 'Franciscans': ['Fransiscans'], 'Gael': ['gae'], 'Galatians': ['Galations'], 'Gandhi': ['Ghandi'], 'Gauguin': ['gogin'], 'Guatemala': ['Guatamala'], 'Guatemalan': ['Guatamalan'], 'Guinness': ['Guiness'], 'Israelis': ['Israelies'], 'Ithaca': ['Ihaca'], 'Jacques': ['Jaques'], 'Ja...\n"
     ]
    }
   ],
   "source": [
    "# -- Testing --\n",
    "def test_dataset_reading():\n",
    "    path_to_misspells_dataset = \"data/wikipedia_misspells.txt\"\n",
    "    misspells_dict = read_misspells_dataset(path_to_misspells_dataset)\n",
    "    print(str(misspells_dict)[:1000] + '...')\n",
    "\n",
    "\n",
    "test_dataset_reading()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build texts on which spell checkers will be tested\n",
    "\n",
    "Now let's build a texts that we will give to the checkers.\n",
    "\n",
    "In parallel, based on the dictionary obtained above, we will generate 2 text string: correct string and string with misspellings.\n",
    "\n",
    "**Why 2 string?**\n",
    "To make it easy to get the correct form of an incorrect word. We will assume that the checker worked correctly if it issued exactly such a correction that matches with the word of the correct string.\n",
    "\n",
    "**What are the requirements for the line with misspellings?**\n",
    "It is necessary that there are both right spelled and misspelled words in the string, in order not just to evaluate how well the checker can correct errors, but also to see if checker does not spoil the originally right spelled words.\n",
    "\n",
    "**How will the strings be created?**\n",
    "We will follow the keys-the correct words lying in the dictionary and do these steps:\n",
    "1. In the misspelled string there will be put right spelled word and then all these incorrect forms (let there be N forms) that lie in the dictionary (values)\n",
    "2. In the correct line, the correct word is also written first, but then follows a sequence of the same correct word repeated N times.\n",
    "\n",
    "Thus, for each word in the misspelled line, its correct version is at the same position in the correct line.\n",
    "\n",
    "All words are separated by spaces."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def build_correct_and_misspell_sentence(misspells_dict: dict):\n",
    "    misspell_str = \"\"\n",
    "    correct_str = \"\"\n",
    "    invalids_in_misspell_str = 0\n",
    "\n",
    "    for correct_word in misspells_dict:\n",
    "        misspelled_forms = misspells_dict[correct_word]\n",
    "        invalids_in_misspell_str += len(misspelled_forms)\n",
    "        misspelled_forms_str = \" \".join(misspelled_forms)\n",
    "        misspell_str += correct_word + ' ' + misspelled_forms_str + ' '\n",
    "\n",
    "        correct_forms = \" \".join([correct_word] * len(misspelled_forms))\n",
    "        correct_str += correct_word + ' ' + correct_forms + ' '\n",
    "\n",
    "    return correct_str, misspell_str, invalids_in_misspell_str"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test sentence building\n",
    "\n",
    "Here we will also display only the first 2000 characters of each generated string on the screen, so as not to clutter the notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct sentence: \n",
      "Apennines Apennines Apennines Athenian Athenian Athenians Athenians Bernoulli Bernoulli Blitzkrieg Blitzkrieg Brazilian Brazilian Britain Britain British British Caesar Caesar Cambridge Cambridge Caracas Caracas Caribbean Caribbean Carthaginian Carthaginian Catalina Catalina Catiline Catiline Celsius Celsius Champagne Champagne Connecticut Connecticut Cypriot Cypriot Ellis Ellis English English European European European European Europeans Europeans February February Flemish Flemish Franciscan Franciscan Franciscans Franciscans Gael Gael Galatians Galatians Gandhi Gandhi Gauguin Gauguin Guatemala Guatemala Guatemalan Guatemalan Guinness Guinness Israelis Israelis Ithaca Ithaca Jacques Jacques Japanese Japanese Joseph Joseph Judaism Judaism Judaism Libya Libya Malcolm Malcolm Maltese Maltese Mara_Liasson Mara_Liasson Massachusetts Massachusetts Massachusetts Mediterranean Mediterranean Michigan Michigan Miranda Miranda Mississippi Mississippi Mississippi Missouri Missouri Muslim Muslim Muslim Muslims Muslims Nazareth Nazareth New_Yorker New_Yorker Newfoundland Newfoundland Nuremberg Nuremberg Orignal Orignal Palestinian Palestinian Palestinian Philippine Philippine Philippines Philippines Philippines Philippines Portuguese Portuguese Puccini Puccini Rockefeller Rockefeller Russian Russian Russian Saturday Saturday Saturdays Saturdays Sistine Sistine Spanish Spanish Tim Tim Ukrainian Ukrainian Valletta Valletta Wednesday Wednesday Wednesday Zionist Zionist Zionists Zionists a_lot a_lot abandon abandon abandoned abandoned abandoning abandoning abandons abandons aberration aberration about about about absence absence absorbed absorbed absorption absorption absorption abuts abuts acceptable acceptable accessible accessible accession accession accidentally accidentally acclimatization acclimatization accommodate accommodate accommodate accommodated accommodated accommodated accommodates accommodates accommodates accommodating accommodating accommodating accommodation acco...\n",
      " -----------------------\n",
      "\n",
      "Misspell sentence: \n",
      "Apennines Apenines Appenines Athenian Athenean Athenians Atheneans Bernoulli Bernouilli Blitzkrieg Blitzkreig Brazilian Brasillian Britain Britian British Brittish Caesar Ceasar Cambridge Cambrige Caracas carcas Caribbean Carribean Carthaginian Carthagian Catalina Cataline Catiline Cataline Celsius Celcius Champagne Champange Connecticut Conneticut Cypriot Cyprian Ellis eles English Enlish European Europian Eurpean Eurpoean Europeans Europians February febuary Flemish Flemmish Franciscan Fransiscan Franciscans Fransiscans Gael gae Galatians Galations Gandhi Ghandi Gauguin gogin Guatemala Guatamala Guatemalan Guatamalan Guinness Guiness Israelis Israelies Ithaca Ihaca Jacques Jaques Japanese Japanes Joseph Jospeh Judaism Juadaism Juadism Libya Lybia Malcolm Malcom Maltese maltesian Mara_Liasson liason Massachusetts Massachussets Massachussetts Mediterranean Mediteranean Michigan Michagan Miranda meranda Mississippi Missisipi Missisippi Missouri Misouri Muslim Mohammedan Muhammadan Muslims Mohammedans Nazareth Nazereth New_Yorker Newyorker Newfoundland Foundland Nuremberg Nuremburg Orignal orginal Palestinian Palistian Palistinian Philippine Phillipine Philippines Philipines Phillipines Phillippines Portuguese Portugese Puccini Pucini Rockefeller Rockerfeller Russian Russion russina Saturday Saterday Saturdays Saterdays Sistine Sixtin Spanish spainish Tim tiem Ukrainian Ukranian Valletta Valetta Wednesday wendsay wensday Zionist Sionist Zionists Sionists a_lot alot abandon abondon abandoned abondoned abandoning abondoning abandons abondons aberration aberation about baout boaut absence absense absorbed asorbed absorption absorbsion absorbtion abuts abutts acceptable acceptible accessible accessable accession accension accidentally accidently acclimatization acclimitization accommodate accomadate accomodate accommodated accomadated accomodated accommodates accomadates accomodates accommodating accomadating accomodating accommodation accomadation accomodation accommodat...\n"
     ]
    }
   ],
   "source": [
    "# -- Testing --\n",
    "def test_sentences_building():\n",
    "    path_to_misspells_dataset = \"data/wikipedia_misspells.txt\"\n",
    "    misspells_dict = read_misspells_dataset(path_to_misspells_dataset)\n",
    "\n",
    "    correct_sentence, misspell_sentence, invalids_in_misspell_str = build_correct_and_misspell_sentence(misspells_dict)\n",
    "    short_correct_sentence = correct_sentence[:2000]\n",
    "    short_misspell_sentence = misspell_sentence[:2000]\n",
    "    print('Correct sentence: \\n' + short_correct_sentence + '...\\n -----------------------\\n')\n",
    "    print('Misspell sentence: \\n' + short_misspell_sentence + '...')\n",
    "\n",
    "\n",
    "test_sentences_building()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics\n",
    "\n",
    "## Metrics group\n",
    "Metrics for spell checker evaluating can be divided into 3 groups:\n",
    "1. Metrics that evaluate the tool's ability to **classify words as right spelled or misspelled**\n",
    "2. Metrics that evaluate the tool's ability to **correct misspelled words**\n",
    "3. Others\n",
    "\n",
    "## Metrics of each group\n",
    "1. To understand the 1st metrics group, this [article](https://gerhard.pro/files/PublicationVanHuyssteenEiselenPuttkammer2004.pdf) can be helpful. I relied on this paper, but changed the approach to putting positive and negative labels, based on the idea that we are still looking for misspelled words (as in the problem of detecting cancerous tumors, we usually label cancerous cases as positives). I chose standard metrics without the additional subdivision, described in the article.\n",
    "\n",
    "    Thus,  there will be used the following metrics:\n",
    "    * **Recall**\n",
    "    * **Precision**\n",
    "    * **Classifying Accuracy**\n",
    "\n",
    "2. In the second group I will use these metrics:\n",
    "    * **Percent of words** that are **invalid after checker work**\n",
    "    * **Percent of the misspelled words**, that were **correctly fixed** by spellchecker\n",
    "    * **Percent of non-fixed misspelled words**, but for which the right decision was **in top-5** spellchecker suggested word **candidates**\n",
    "    * **Percent of** originally correct spelled words that were **broken** by the checker\n",
    "\n",
    "3. In 3rd group there was put one metric:\n",
    "    * Checker work **speed**\n",
    "\n",
    "## Formulas and explanation of each metric\n",
    "\n",
    "As we are looking for misspelled words, positive labels will be set for invalid words with the misspellings, negative labels -- for valid correct spelled words.\n",
    "\n",
    "In that way:\n",
    "* **True positives (tp)** -- invalid words, recognized by spelling checker as misspelled.\n",
    "* **False positives (fp)** -- valid words, recognized by checker as misspelled.\n",
    "* **True negatives (tn)** -- valid words, recognized by checker as right spelled.\n",
    "* **False negatives (fn)** -- invalid words, recognized by checker as right spelled.\n",
    "\n",
    "### 1. Recall\n",
    "\n",
    "Recall -- number of invalid words that were recognized by the checker as misspelled (true positives), in relation to the total number of invalid words in the text (sum of true positives and false negatives)\n",
    "\n",
    "$$ recall = \\frac{tp}{tp + fn} $$\n",
    "\n",
    "The ideal for the spelling checker -- to recognize all invalid words as misspelled $\\Rightarrow$ to get as high recall as possible, the closer to 100% the better.\n",
    "Recall indicates comprehensiveness of the lexicon of the spelling checker and whether the spelling checker lexicon contains any erroneous words.\n",
    "\n",
    "### 2. Precision\n",
    "\n",
    "Precision -- number of words, that were marked by checker as misspelled and which are really incorrect, in relation to the total number of words, that checker marked as misspelled (sum of true positives and false positives).\n",
    "\n",
    "$$ precision = \\frac{tp}{tp + fp} $$\n",
    "\n",
    "The ideal for the checker -- to recognize all invalid and only invalid words as misspelled $\\Rightarrow$ to get as high precision as possible, the closer to 100% the better.\n",
    "Precision indicates how accurate is the spelling checker in assigning misspell flag.\n",
    "\n",
    "### 3. Identifying Accuracy\n",
    "\n",
    "Accuracy shows what the spelling checker does right (the sum of true positives and true negatives) in terms of everything the spelling checker does (all true and false positives and negatives).\n",
    "\n",
    "$$ identifyingAccuracy = \\frac{tp + tn}{tp + fp + tn + fn} $$\n",
    "\n",
    "This gives a good overall view of the competence of a checker, since it determines how accurate a spelling checker is at performing the errand it was sent on. The better spell checking tool works, the higher accuracy $\\Rightarrow$ the ideal for the checker -- to get 100% accuracy.\n",
    "\n",
    "### 4. Percent of words that are invalid after checker work\n",
    "$$ invalidsAfterCheckerPerc = \\frac{invalidsAfterCheckerWork}{nWordsInText} $$\n",
    "The ideal for spellchecker -- 0% -- when all words in text after checker work are valid. The lower, the better.\n",
    "\n",
    "### 5. Percent of correctly fixed misspellings\n",
    "\n",
    "$$ fixedMisspellingsPerc = \\frac{fixedMisspellings}{allMisspellsInText} $$\n",
    "\n",
    "The ideal for spellchecker -- 100%. The higher, the better.\n",
    "\n",
    "### 6. Percent of non-fixed misspellings but with right correction in top-5 candidates\n",
    "\n",
    "$$ notFixedButInTop5Perc = \\frac{notFixedButCorrectionInTop5Candidates}{notFixedMisspells} $$\n",
    "\n",
    "The ideal for spellchecker -- 100% -- when all not fixed misspells had right correction in top-5 candidates. The higher, the better.\n",
    "\n",
    "### 7. Percent of broken valid words\n",
    "\n",
    "$$ brokenValidsPerc = \\frac{brokenValids}{allOriginallyValids} $$\n",
    "\n",
    "The ideal for spellchecker -- 0% -- when it didn't break a single word. The lower, the better.\n",
    "\n",
    "### 8. Speed\n",
    "\n",
    "Calculates number of words per second and shows how fast the spell checking tool copes with data processing. Can be calculated as the total time spent by the spell checker for processing the dataset, divided by the number of words processed by it:\n",
    "\n",
    "$$ speed = \\frac{numberOfWordsInText}{totalCheckerTextProcessingTime} $$\n",
    "\n",
    "The higher the speed of the checker, the less the user will have to wait $\\Rightarrow$ the higher speed the better."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating 1st metrics group"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def calculate_main_metrics(tp: int, fp: int, tn: int, fn: int):\n",
    "    recall = float(tp) / (tp + fn)\n",
    "    precision = float(tp) / (tp + fp)\n",
    "    accuracy = float(tp + tn) / (tp + fp + tn + fn)\n",
    "    return recall, precision, accuracy\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spell checking tools\n",
    "\n",
    "### Selected tools\n",
    "\n",
    "We will consider 6 speech checking tools:\n",
    "1. *Pyspellchecker* library\n",
    "2. *Textblob* library\n",
    "3. Pre-trained model from *Spello* library\n",
    "4. *Hunspell* spelling corrector\n",
    "5. *Jamspell* spelling corrector\n",
    "6. *Autocorrect* library\n",
    "\n",
    "### Base SpellCorrector class description\n",
    "\n",
    "For the convenience of working with these tools, a base class *SpellCorrector* was created and each spell checker was wrapped in a class-inheritor of the SpellCorrector.\n",
    "\n",
    "SpellCorrector has method *correct* that takes as input a list of words and the position of the analyzed word in it. Almost all tools could be given just an analyzed word as input, but the Jamspell interface requires that a list of words and a position be given, so for uniformity, all methods are built this way.\n",
    "\n",
    "As the output method *correct* returns one of two:\n",
    "* either single word (**str** type) that matches the original one -- this means that the checker considered the word given to him as right spelled and did not correct it\n",
    "* either a **list** of all candidates that the spell checker suggested for the word -- in this case, we believe that the checker classifies the word submitted to him as incorrect and tries to correct it\n",
    "\n",
    "## IMPORTANT! Models downloading\n",
    "\n",
    "For some analyzed tools, it's necessary to download model files before code running.\n",
    "\n",
    "I can't upload them to the GitHub due to their large size, so to run the code you need to follow these steps:\n",
    "1. Create dir named 'models' in the project directory 'spell-checkers-comparison'\n",
    "2. Download [file](http://downloads.sourceforge.net/wordlist/hunspell-en_US-2020.12.07.zip) for Hunspell\n",
    "3. Download [file](https://haptik-website-images.haptik.ai/spello_models/en.pkl.zip) for Spello\n",
    "4. Download [file](https://github.com/bakwc/JamSpell-models/raw/master/en.tar.gz) for Jamspell\n",
    "5. Unzip downloaded files\n",
    "6. Place model files in the created folder 'models' or you can specify the paths to your files in the classes.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import spellchecker\n",
    "from spello.model import SpellCorrectionModel\n",
    "import spello.settings as ss\n",
    "import hunspell\n",
    "import jamspell\n",
    "import textblob\n",
    "import autocorrect\n",
    "\n",
    "# for 'Spello' logging and warnings\n",
    "ss.logger.disabled = True\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spell checker classes creation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "class SpellCorrector(object):\n",
    "    def __init__(self, name):\n",
    "        self.__name = name\n",
    "\n",
    "    def correct(self, sentence: list, position: int):\n",
    "        pass\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.__name\n",
    "\n",
    "\n",
    "class PyspellcheckerCorrector(SpellCorrector):\n",
    "    def __init__(self):\n",
    "        super(PyspellcheckerCorrector, self).__init__(\"Pyspellchecker\")\n",
    "        self.__spellchecker = spellchecker.SpellChecker()\n",
    "\n",
    "    def correct(self, sentence: list, position: int):\n",
    "        word = sentence[position]\n",
    "        self.__spellchecker.unknown([word])\n",
    "        correction_candidates = self.__spellchecker.candidates(word)\n",
    "        if correction_candidates is None:\n",
    "            return word\n",
    "        return list(correction_candidates)\n",
    "\n",
    "\n",
    "class TextblobCorrector(SpellCorrector):\n",
    "    def __init__(self):\n",
    "        super(TextblobCorrector, self).__init__(\"Textblob\")\n",
    "\n",
    "    def correct(self, sentence: list, position: int):\n",
    "        word_str = sentence[position]\n",
    "        blob_word = textblob.Word(word_str)\n",
    "        correction_candidates = blob_word.spellcheck()\n",
    "        if len(correction_candidates) == 0:\n",
    "            return word_str\n",
    "        return [word_prob[0] for word_prob in correction_candidates]\n",
    "\n",
    "\n",
    "class SpelloCorrector(SpellCorrector):\n",
    "    def __init__(self, spello_model_path: str = \"models/spello-en.pkl\"):\n",
    "        super(SpelloCorrector, self).__init__(\"Spello\")\n",
    "        self.__spellchecker = SpellCorrectionModel(language='en')\n",
    "        self.__spellchecker.load(spello_model_path)\n",
    "\n",
    "    def correct(self, sentence: list, position: int):\n",
    "        word = sentence[position]\n",
    "        correction_candidates = self.__spellchecker.suggest(word)\n",
    "        if len(correction_candidates) == 0:\n",
    "            return word\n",
    "        return [word_prob[0] for word_prob in correction_candidates]\n",
    "\n",
    "\n",
    "class HunspellCorrector(SpellCorrector):\n",
    "    def __init__(self, hunspell_model_path: str = \"models/hunspell-en_US/en_US\"):\n",
    "        super(HunspellCorrector, self).__init__(\"Hunspell\")\n",
    "        self.__spellchecker = hunspell.HunSpell(hunspell_model_path + '.dic',\n",
    "                                                hunspell_model_path + '.aff')\n",
    "\n",
    "    def correct(self, sentence: list, position: int):\n",
    "        word = sentence[position]\n",
    "        # spellchecker thinks that this word is correct\n",
    "        if self.__spellchecker.spell(word):\n",
    "            return word\n",
    "        return self.__spellchecker.suggest(word)\n",
    "\n",
    "\n",
    "class JamspellCorrector(SpellCorrector):\n",
    "    def __init__(self, jamspell_model_path: str = \"models/jamspell-en.bin\"):\n",
    "        super(JamspellCorrector, self).__init__(\"Jamspell\")\n",
    "        self.__spellchecker = jamspell.TSpellCorrector()\n",
    "        self.__spellchecker.LoadLangModel(jamspell_model_path)\n",
    "\n",
    "    def correct(self, sentence: list, position: int):\n",
    "        correction_candidates = list(self.__spellchecker.GetCandidates(sentence, position))\n",
    "        # spellchecker thinks that this word is correct\n",
    "        if len(correction_candidates) == 0:\n",
    "            return sentence[position]\n",
    "        return correction_candidates\n",
    "\n",
    "\n",
    "class AutocorrectCorrector(SpellCorrector):\n",
    "    def __init__(self):\n",
    "        super(AutocorrectCorrector, self).__init__(\"Autocorrect\")\n",
    "        self.__spellchecker = autocorrect.Speller()\n",
    "\n",
    "    def correct(self, sentence: list, position: int):\n",
    "        word = sentence[position]\n",
    "        correction_candidates = self.__spellchecker.get_candidates(word)\n",
    "        if len(correction_candidates) == 0:\n",
    "            return word\n",
    "        return [word_prob[1] for word_prob in correction_candidates]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The checker will alternately receive words from the misspelled sentence, we will see how it copes with its task and count metrics in parallel:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def evaluate_checker(spellchecker: SpellCorrector, correct_sentence: str, misspell_sentence: str,\n",
    "                     invalids_in_misspell_sentence: int):\n",
    "    # values for metrics calculation\n",
    "    invalid_recognized_misspelled = 0\n",
    "    valid_recognized_misspelled = 0\n",
    "    invalid_recognized_correct = 0\n",
    "    valid_recognized_correct = 0\n",
    "\n",
    "    fixed_invalids = 0\n",
    "    broken_valids = 0\n",
    "    not_fixed_invalids = 0\n",
    "    not_fixed_but_correction_in_top5 = 0\n",
    "\n",
    "    checker_worktime = 0\n",
    "\n",
    "    correct_sentence_words = correct_sentence.split()\n",
    "    misspell_sentence_words = misspell_sentence.split()\n",
    "\n",
    "    n_words = len(misspell_sentence_words)\n",
    "    for pos in range(n_words):\n",
    "        misspell_sentence_word = misspell_sentence_words[pos]\n",
    "        correct_sentence_word = correct_sentence_words[pos]\n",
    "\n",
    "        # mark the time of operation of the correct function\n",
    "        correction_start_time = time.time()\n",
    "        checker_correction_candidates = spellchecker.correct(misspell_sentence_words, pos)\n",
    "        checker_worktime += time.time() - correction_start_time\n",
    "\n",
    "        if isinstance(checker_correction_candidates, list):\n",
    "            word_recognized_correct = False\n",
    "            checker_word_correction = checker_correction_candidates[0]\n",
    "            top5_correction_candidates = checker_correction_candidates[:5] if \\\n",
    "                len(checker_word_correction) >= 5 else checker_correction_candidates\n",
    "        else:\n",
    "            word_recognized_correct = True\n",
    "            checker_word_correction = checker_correction_candidates\n",
    "            top5_correction_candidates = [checker_word_correction]\n",
    "\n",
    "        # the word was originally correct\n",
    "        if misspell_sentence_word == correct_sentence_word:\n",
    "            # checker recognized word as correct\n",
    "            if word_recognized_correct:\n",
    "                valid_recognized_correct += 1\n",
    "            else:\n",
    "                # checker recognized word as misspelled\n",
    "                valid_recognized_misspelled += 1\n",
    "                # if checker suggested the wrong replacement, it brakes out the word\n",
    "                if checker_word_correction != correct_sentence_word:\n",
    "                    broken_valids += 1\n",
    "        else:\n",
    "            # the word was originally misspelled\n",
    "            # checker recognized word as correct\n",
    "            if word_recognized_correct:\n",
    "                invalid_recognized_correct += 1\n",
    "            else:\n",
    "                # checker recognized word as misspelled\n",
    "                invalid_recognized_misspelled += 1\n",
    "                # if checker suggested the correct replacement, it fixes the word\n",
    "                if checker_word_correction == correct_sentence_word:\n",
    "                    fixed_invalids += 1\n",
    "                else:\n",
    "                    not_fixed_invalids += 1\n",
    "                    # if the word wasn't fixed, but right correction was in top5 candidates\n",
    "                    if correct_sentence_word in top5_correction_candidates:\n",
    "                        not_fixed_but_correction_in_top5 += 1\n",
    "\n",
    "    misspells_after_checker = invalids_in_misspell_sentence - fixed_invalids + broken_valids\n",
    "\n",
    "    # calculating metrics\n",
    "    recall, precision, accuracy = calculate_main_metrics(invalid_recognized_misspelled,\n",
    "                                                         valid_recognized_misspelled,\n",
    "                                                         valid_recognized_correct,\n",
    "                                                         invalid_recognized_correct)\n",
    "    misspells_after_checker_percent = float(misspells_after_checker) / n_words\n",
    "    fixed_invalids_percent = float(fixed_invalids) / invalids_in_misspell_sentence\n",
    "    not_fixed_invalids_but_correction_in_top5_percent = float(not_fixed_but_correction_in_top5) / not_fixed_invalids\n",
    "    broken_valids_percent = float(broken_valids) / (n_words - invalids_in_misspell_sentence)\n",
    "    speed = float(n_words) / checker_worktime\n",
    "\n",
    "    return recall * 100, \\\n",
    "           precision * 100, \\\n",
    "           accuracy * 100, \\\n",
    "           misspells_after_checker_percent * 100, \\\n",
    "           fixed_invalids_percent * 100, \\\n",
    "           not_fixed_invalids_but_correction_in_top5_percent * 100, \\\n",
    "           broken_valids_percent * 100, \\\n",
    "        speed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def calculate_metrics_and_print(spellchecker: SpellCorrector, misspells_dict: dict):\n",
    "    correct_sentence, misspell_sentence, invalids_in_misspell_sentence = build_correct_and_misspell_sentence(\n",
    "        misspells_dict)\n",
    "\n",
    "    recall, \\\n",
    "        precision, \\\n",
    "        accuracy, \\\n",
    "        misspells_after_checker_percent, \\\n",
    "        fixed_invalids_percent, \\\n",
    "        not_fixed_invalids_but_correction_in_top5_percent, \\\n",
    "        broken_valids_percent, \\\n",
    "        speed = evaluate_checker(spellchecker, correct_sentence, misspell_sentence, invalids_in_misspell_sentence)\n",
    "\n",
    "    print(\"Checker: {0}\\n\"\n",
    "          \"Classifying recall: {1:.2f} %\\n\"\n",
    "          \"Classifying precision: {2:.2f} %\\n\"\n",
    "          \"Classifying accuracy: {3:.2f} %\\n\"\n",
    "          \"Misspells after checker percent: {4:.2f} %\\n\"\n",
    "          \"Fixed misspellings percent: {5:.2f} %\\n\"\n",
    "          \"Not fixed but may be corrected by one in top-5 percent: {6:.2f} %\\n\"\n",
    "          \"Broken valids percent: {7:.2f} %\\n\"\n",
    "          \"Speed: {8:.7f} words/ sec\\n\"\n",
    "          \"----------------------------\".format(spellchecker.get_name(),\n",
    "                                                recall,\n",
    "                                                precision,\n",
    "                                                accuracy,\n",
    "                                                misspells_after_checker_percent,\n",
    "                                                fixed_invalids_percent,\n",
    "                                                not_fixed_invalids_but_correction_in_top5_percent,\n",
    "                                                broken_valids_percent,\n",
    "                                                speed))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def compare_spellcheckers():\n",
    "    path_to_misspells_dataset = \"data/wikipedia_misspells.txt\"\n",
    "    misspells_dict = read_misspells_dataset(path_to_misspells_dataset)\n",
    "\n",
    "    correctors = [PyspellcheckerCorrector(),\n",
    "                  SpelloCorrector(),\n",
    "                  HunspellCorrector(),\n",
    "                  JamspellCorrector(),\n",
    "                  TextblobCorrector(),\n",
    "                  AutocorrectCorrector()\n",
    "                  ]\n",
    "\n",
    "    for corrector in correctors:\n",
    "        calculate_metrics_and_print(corrector, misspells_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checker: Pyspellchecker\n",
      "Classifying recall: 97.59 %\n",
      "Classifying precision: 55.87 %\n",
      "Classifying accuracy: 55.45 %\n",
      "Misspells after checker percent: 21.73 %\n",
      "Fixed misspellings percent: 63.79 %\n",
      "Not fixed but may be corrected by one in top-5 percent: 57.85 %\n",
      "Broken valids percent: 3.23 %\n",
      "Speed: 31.9817255 words/ sec\n",
      "----------------------------\n",
      "Checker: Spello\n",
      "Classifying recall: 96.90 %\n",
      "Classifying precision: 90.86 %\n",
      "Classifying accuracy: 92.80 %\n",
      "Misspells after checker percent: 22.53 %\n",
      "Fixed misspellings percent: 69.57 %\n",
      "Not fixed but may be corrected by one in top-5 percent: 47.68 %\n",
      "Broken valids percent: 12.43 %\n",
      "Speed: 929.9438380 words/ sec\n",
      "----------------------------\n",
      "Checker: Hunspell\n",
      "Classifying recall: 98.78 %\n",
      "Classifying precision: 97.31 %\n",
      "Classifying accuracy: 97.78 %\n",
      "Misspells after checker percent: 15.01 %\n",
      "Fixed misspellings percent: 75.97 %\n",
      "Not fixed but may be corrected by one in top-5 percent: 67.74 %\n",
      "Broken valids percent: 3.49 %\n",
      "Speed: 62.9287733 words/ sec\n",
      "----------------------------\n",
      "Checker: Jamspell\n",
      "Classifying recall: 99.71 %\n",
      "Classifying precision: 56.06 %\n",
      "Classifying accuracy: 56.04 %\n",
      "Misspells after checker percent: 21.64 %\n",
      "Fixed misspellings percent: 64.97 %\n",
      "Not fixed but may be corrected by one in top-5 percent: 60.87 %\n",
      "Broken valids percent: 4.53 %\n",
      "Speed: 365.1616550 words/ sec\n",
      "----------------------------\n",
      "Checker: Textblob\n",
      "Classifying recall: 100.00 %\n",
      "Classifying precision: 56.04 %\n",
      "Classifying accuracy: 56.04 %\n",
      "Misspells after checker percent: 28.03 %\n",
      "Fixed misspellings percent: 61.63 %\n",
      "Not fixed but may be corrected by one in top-5 percent: 26.06 %\n",
      "Broken valids percent: 14.83 %\n",
      "Speed: 10.1833535 words/ sec\n",
      "----------------------------\n",
      "Checker: Autocorrect\n",
      "Classifying recall: 100.00 %\n",
      "Classifying precision: 56.04 %\n",
      "Classifying accuracy: 56.04 %\n",
      "Misspells after checker percent: 23.62 %\n",
      "Fixed misspellings percent: 64.81 %\n",
      "Not fixed but may be corrected by one in top-5 percent: 44.66 %\n",
      "Broken valids percent: 8.84 %\n",
      "Speed: 42.4648874 words/ sec\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "compare_spellcheckers()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Pyspellchecker library\n",
    "\n",
    "### Work principles description\n",
    "\n",
    "Spell checking [library](https://github.com/barrust/pyspellchecker) that implements [Peter Norvig's](https://norvig.com/spell-correct.html) algorithm idea, which many subsequently turned to for comparison or improvement.\n",
    "\n",
    "**How does it work?**\n",
    "Clipping from the library description:\n",
    "\n",
    "\"It uses a [Levenshtein Distance](https://en.wikipedia.org/wiki/Levenshtein_distance) algorithm to find permutations within an edit distance of 2 from the original word. It then compares all permutations (insertions, deletions, replacements, and transpositions) to known words in a word frequency list. Those words that are found more often in the frequency list are more likely the correct results.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Pre-trained spell correction model 'Spello'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Hunspell library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. JamSpell library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Textblob library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Autocorrect library"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
